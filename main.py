import asyncio
import feedparser
from telegram import Bot
from datetime import datetime, timedelta
import os
import re
from googletrans import Translator

print("âœ… Bot is starting...")

TOKEN = "8101036051:AAEMbhWIYv22FOMV6pXcAOosEWxsy9v3jfY"
CHANNEL = "@USMarketnow"
bot = Bot(token=TOKEN)
translator = Translator()

RSS_FEEDS = [
    "https://finance.yahoo.com/news/rssindex",
    "https://www.cnbc.com/id/100003114/device/rss/rss.html",
    "https://sa.investing.com/rss/news_301.rss"
]

KEYWORDS = [
    "Ø¨Ø§ÙˆÙ„", "Ø§Ù„ÙØ§Ø¦Ø¯Ø©", "Ø±ÙØ¹ Ø§Ù„ÙØ§Ø¦Ø¯Ø©", "Ø®ÙØ¶ Ø§Ù„ÙØ§Ø¦Ø¯Ø©", "Ø§Ù„Ø¨ÙŠØª Ø§Ù„Ø£Ø¨ÙŠØ¶", "ØªØ±Ø§Ù…Ø¨", "Ø¨Ø§ÙŠØ¯Ù†",
    "Ø£ÙˆØ¨Ùƒ", "cpi", "Ø§Ù„ØªØ¶Ø®Ù…", "ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙˆØ¸Ø§Ø¦Ù", "Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠ", "Ø§Ù„Ø±ÙƒÙˆØ¯", "Ø§Ù„Ø§Ù†ÙƒÙ…Ø§Ø´",
    "Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ù…Ù„", "Ø§Ù„Ø°Ù‡Ø¨", "Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±", "Ø§Ù„Ø¨Ø·Ø§Ù„Ø©", "Ø§Ù„ÙƒÙˆÙ†ØºØ±Ø³", "Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ",
    "Ø§Ù„Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª", "Ø¶Ø±Ø¨Ø©", "Ù‡Ø¬ÙˆÙ…", "Ù‚ØµÙ", "Ø¥ÙŠØ±Ø§Ù†", "Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„", "Ø§Ù„Ù†ÙØ·", "Ø£Ø±Ø¨Ø§Ø­", "Ø§Ù„Ø­Ø±Ø¨",
    "Ø³Ø¨Ø§ÙƒØ³", "spx", "s&p500", "Ø§Ù„Ø¯Ø§Ùˆ", "Ø§Ù„Ø¯Ø§Ùˆ Ø¬ÙˆÙ†Ø²", "ÙˆÙˆÙ„ Ø³ØªØ±ÙŠØª"
]

SENT_FILE = "sent_titles.txt"

def load_sent_titles():
    if not os.path.exists(SENT_FILE):
        return set()
    with open(SENT_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

def save_sent_title(title):
    with open(SENT_FILE, "a", encoding="utf-8") as f:
        f.write(title.strip() + "\n")

def is_recent(entry):
    if not hasattr(entry, 'published_parsed'):
        return True
    pub_time = datetime(*entry.published_parsed[:6])
    return pub_time > datetime.utcnow() - timedelta(hours=3)

def is_important(text):
    return any(word.lower() in text.lower() for word in KEYWORDS)

def clean_text(text):
    return re.sub(r'[*_`]', '', text)

def is_arabic_feed(url):
    return "investing.com" in url

def extract_title(text):
    text = text.lower()
    if "powell" in text or "Ø¨Ø§ÙˆÙ„" in text:
        return "ğŸ”´ Ø¹Ø§Ø¬Ù„ | Ø¬ÙŠØ±ÙˆÙ… Ø¨Ø§ÙˆÙ„ ÙŠØªØ­Ø¯Ø«"
    elif "interest rate" in text or "Ø§Ù„ÙØ§Ø¦Ø¯Ø©" in text:
        return "ğŸ“Š Ø¹Ø§Ø¬Ù„ | Ù‚Ø±Ø§Ø± Ø§Ù„ÙØ§Ø¦Ø¯Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©"
    elif "white house" in text or "Ø§Ù„Ø¨ÙŠØª Ø§Ù„Ø£Ø¨ÙŠØ¶" in text:
        return "ğŸ›ï¸ Ø¹Ø§Ø¬Ù„ | Ø§Ù„Ø¨ÙŠØª Ø§Ù„Ø£Ø¨ÙŠØ¶"
    elif "trump" in text or "ØªØ±Ø§Ù…Ø¨" in text:
        return "ğŸ‡ºğŸ‡¸ Ø¹Ø§Ø¬Ù„ | ØªØµØ±ÙŠØ­Ø§Øª ØªØ±Ø§Ù…Ø¨"
    elif "biden" in text or "Ø¨Ø§ÙŠØ¯Ù†" in text:
        return "ğŸŸ¦ Ø¹Ø§Ø¬Ù„ | ØªØµØ±ÙŠØ­Ø§Øª Ø¨Ø§ÙŠØ¯Ù†"
    elif "cpi" in text or "Ø§Ù„ØªØ¶Ø®Ù…" in text:
        return "ğŸ“‰ Ø¹Ø§Ø¬Ù„ | Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¶Ø®Ù…"
    elif "jobs report" in text or "ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙˆØ¸Ø§Ø¦Ù" in text:
        return "ğŸ“‹ Ø¹Ø§Ø¬Ù„ | ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ"
    elif "opec" in text or "Ø£ÙˆØ¨Ùƒ" in text:
        return "ğŸ›¢ï¸ Ø¹Ø§Ø¬Ù„ | ØªØµØ±ÙŠØ­Ø§Øª Ù…Ù† Ø£ÙˆØ¨Ùƒ"
    elif "war" in text or "Ø§Ù„Ø­Ø±Ø¨" in text or "strike" in text:
        return "ğŸ’¥ Ø¹Ø§Ø¬Ù„ | ØªÙˆØªØ±Ø§Øª Ø¬ÙŠÙˆØ³ÙŠØ§Ø³ÙŠØ©"
    else:
        return "ğŸ“° Ø¹Ø§Ø¬Ù„ | Ø®Ø¨Ø± Ø§Ù‚ØªØµØ§Ø¯ÙŠ Ù…Ø¤Ø«Ø±"

def format_message(entry, arabic_source=False):
    title = entry.title.strip()
    description = entry.get("description", "") or ""
    full_text = f"{title} {description}"

    # Ø§Ù„ØªØ±Ø¬Ù…Ø©
    if not arabic_source:
        try:
            full_text = translator.translate(full_text, dest='ar').text
        except Exception as e:
            print("âš ï¸ ÙØ´Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø©:", e)
            full_text = full_text[:300]

    full_text = clean_text(full_text)

    if len(full_text) > 350:
        full_text = full_text[:350] + "..."

    headline = extract_title(full_text)
    footer = "\n\nğŸ“ [Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø¨Ø±]({})\n\nğŸ“¡ Ù‚Ù†Ø§Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø§Ù„Ø¹Ø§Ø¬Ù„Ø©\nhttps://t.me/USMarketnow".format(entry.link)
    return f"{headline}\n\n{full_text}{footer}"

async def send_news():
    sent_titles = load_sent_titles()
    news_sent = 0
    print("ğŸ” Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")

    for url in RSS_FEEDS:
        arabic = is_arabic_feed(url)
        feed = feedparser.parse(url)

        for entry in feed.entries:
            title = entry.title.strip()
            if news_sent >= 5 or not is_recent(entry) or title in sent_titles:
                continue

            content = title + " " + (entry.get("description", "") or "")
            if not is_important(content):
                continue

            msg = format_message(entry, arabic_source=arabic)

            try:
                await bot.send_message(chat_id=CHANNEL, text=msg, parse_mode="Markdown", disable_web_page_preview=True)
                print("âœ… Ø£ÙØ±Ø³Ù„:", title)
                save_sent_title(title)
                news_sent += 1
                await asyncio.sleep(1)
            except Exception as e:
                print("âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„:", e)

async def loop_forever():
    while True:
        try:
            await send_news()
        except Exception as e:
            print("âŒ Ø®Ø·Ø£ Ø¹Ø§Ù…:", e)
        await asyncio.sleep(300)

if __name__ == "__main__":
    asyncio.run(loop_forever())
